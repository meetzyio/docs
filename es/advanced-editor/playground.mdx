---
title: 'Playground'
description: 'Prueba tu agente de IA en tiempo real sin hacer llamadas telef√≥nicas'
icon: 'gamepad'
---

## ¬øQu√© es el Playground?

El Playground es un entorno de pruebas en el Editor Avanzado donde puedes interactuar con tu agente en tiempo real. Te permite simular conversaciones, probar diferentes escenarios y validar el comportamiento de tu agente antes de desplegar a producci√≥n.

<Info>
Probar en el Playground ahorra tiempo y dinero al detectar problemas antes de que afecten a llamadas reales de clientes.
</Info>

## Accediendo al Playground

El Playground est√° ubicado en el panel derecho del Editor Avanzado. Haz clic en la pesta√±a "Playground" para acceder.

## Tipos de Llamada

Puedes simular dos tipos de llamadas:

| Tipo | Descripci√≥n | Caso de Uso |
|------|-------------|----------|
| üìû Entrante | Cliente llamando a tu agente | Probar flujo de bienvenida, escenarios de soporte |
| üì§ Saliente | Agente llamando a un cliente | Probar introducciones, scripts de ventas |

<Tip>
Cambia entre tipos de llamada para probar ambos saludos y asegurar que tu agente maneja cada escenario correctamente.
</Tip>

## Enviando Mensajes

### Entrada de Texto

Escribe mensajes en el campo de entrada y presiona Enter o haz clic en Enviar. El agente responder√° como lo har√≠a en una llamada real.

### Entrada de Voz

Haz clic en el icono del micr√≥fono para decir tu mensaje. El agente:
1. Transcribir√° tu voz
2. Procesar√° el mensaje
3. Responder√° con voz sintetizada

<Info>
Las pruebas de voz ayudan a verificar la precisi√≥n del reconocimiento de voz y la calidad de la s√≠ntesis de voz.
</Info>

## Vista de Conversaci√≥n

El Playground muestra mensajes cronol√≥gicamente:

| Elemento | Descripci√≥n |
|---------|-------------|
| üë§ Mensaje de Usuario | Tus entradas (texto o voz transcrita) |
| ü§ñ Mensaje del Agente | Respuestas del agente |
| üîß Llamada de Herramienta | Cuando el agente dispara un webhook o acci√≥n |
| ‚úÖ Resultado de Herramienta | Respuesta del webhook o acci√≥n |

### Reproducci√≥n de Audio

Para cada respuesta del agente, puedes:
- ‚ñ∂Ô∏è Reproducir la respuesta de audio
- ‚è∏Ô∏è Pausar reproducci√≥n
- üîÅ Repetir mensajes

## Variables de Contexto

Prueba c√≥mo tu agente maneja diferentes par√°metros de entrada:

<Steps>
  <Step title="Abrir Variables de Contexto">
    Haz clic en el panel "Variables de Contexto" en el Playground.
  </Step>
  <Step title="Establecer Valores">
    Ingresa valores de prueba para cada par√°metro de entrada.
  </Step>
  <Step title="Iniciar Conversaci√≥n">
    Comienza a probar con el contexto configurado.
  </Step>
</Steps>

### Ejemplo de Contexto

```json
{
  "nombre_cliente": "Juan Garc√≠a",
  "numero_pedido": "PED-12345",
  "es_cliente_premium": true,
  "saldo_cuenta": 1250.50
}
```

## Test de Fiabilidad

Ejecuta m√∫ltiples iteraciones de la misma conversaci√≥n para probar consistencia:

<Steps>
  <Step title="Configurar Escenario">
    Configura tu conversaci√≥n de prueba y variables de contexto.
  </Step>
  <Step title="Establecer Iteraciones">
    Elige cu√°ntas veces ejecutar la prueba (ej., 10, 50, 100).
  </Step>
  <Step title="Ejecutar Prueba">
    Haz clic en "Ejecutar Test de Fiabilidad" para comenzar.
  </Step>
  <Step title="Revisar Resultados">
    Analiza la consistencia en todas las iteraciones.
  </Step>
</Steps>

<Info>
Los tests de fiabilidad ayudan a identificar casos edge donde el agente podr√≠a comportarse inconsistentemente.
</Info>

## Probando Caracter√≠sticas

### Probar Llamadas de Herramientas

Cuando tu agente dispara un webhook:

1. La llamada de herramienta aparece en la conversaci√≥n
2. Puedes ver los par√°metros que se env√≠an
3. La respuesta (o respuesta simulada) se muestra

### Probar Evaluaciones

Despu√©s de una conversaci√≥n, puedes ejecutar evaluaciones para verificar que funcionan correctamente:

1. Termina la conversaci√≥n naturalmente
2. Haz clic en "Ejecutar Evaluaciones"
3. Revisa qu√© evaluaciones pasan o fallan

### Probar Base de Conocimiento

Verifica que tu agente puede encontrar y usar contenido de la base de conocimiento:

1. Haz preguntas que requieran b√∫squeda en KB
2. Observa si el agente recupera informaci√≥n correcta
3. Verifica si las respuestas son precisas y relevantes

## Mejores Pr√°cticas

<AccordionGroup>
  <Accordion title="Prueba Casos Edge" icon="flask">
    Prueba entradas inusuales, interrupciones y respuestas inesperadas para ver c√≥mo las maneja tu agente.
  </Accordion>
  <Accordion title="Var√≠a el Contexto" icon="shuffle">
    Prueba con diferentes combinaciones de par√°metros de entrada para asegurar que la personalizaci√≥n funciona correctamente.
  </Accordion>
  <Accordion title="Prueba Ambos Tipos de Llamada" icon="phone">
    Siempre prueba escenarios tanto entrantes como salientes.
  </Accordion>
  <Accordion title="Verifica Integraciones de Herramientas" icon="plug">
    Verifica que los webhooks se llaman con los par√°metros correctos.
  </Accordion>
  <Accordion title="Ejecuta Tests de Fiabilidad" icon="rotate">
    Ejecuta peri√≥dicamente tests de m√∫ltiples iteraciones para asegurar consistencia.
  </Accordion>
</AccordionGroup>

## Escenarios Comunes de Prueba

### Camino Feliz
Prueba el flujo de conversaci√≥n ideal donde todo va como se espera.

### Manejo de Errores
Prueba qu√© pasa cuando:
- El usuario proporciona informaci√≥n inv√°lida
- Los webhooks fallan
- El usuario no responde

### Manejo de Objeciones
Prueba c√≥mo responde el agente a:
- "No estoy interesado"
- "Ll√°mame m√°s tarde"
- "Necesito pensarlo"

### Casos Edge
Prueba escenarios inusuales:
- Respuestas muy cortas
- Entradas largas y divagantes
- Preguntas fuera de tema
- M√∫ltiples preguntas a la vez

## Troubleshooting

| Problema | Soluci√≥n |
|-------|----------|
| Agente no responde | Verifica que el modelo LLM est√° configurado correctamente |
| Saludo incorrecto | Verifica que el tipo de llamada (entrante/saliente) est√° configurado correctamente |
| Falta personalizaci√≥n | Asegura que las variables de contexto est√°n configuradas |
| Webhook no se dispara | Verifica descripciones y condiciones de herramientas |
| Respuestas lentas | Prueba con un modelo LLM m√°s r√°pido |

## Siguientes Pasos

<CardGroup cols={2}>
  <Card
    title="Copilot"
    icon="robot"
    href="/es/advanced-editor/copilot"
  >
    Obt√©n ayuda de IA para mejorar tus prompts
  </Card>
  <Card
    title="Historial de Versiones"
    icon="clock-rotate-left"
    href="/es/advanced-editor/version-history"
  >
    Rastrea y gestiona cambios
  </Card>
</CardGroup>
